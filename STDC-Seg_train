#!/usr/bin/python
# -*- encoding: utf-8 -*-

from logger import setup_logger
# 实现日志记录功能
from models.model_stages import BiSeNet
from cityscapes import CityScapes
from loss.loss import OhemCELoss
from loss.detail_loss import DetailAggregateLoss
from evaluation import MscEvalV0
# MscEvalV0 则是一个用于图像分割任务的评估类，可以帮助我们计算模型在测试集上的 IoU（Intersection-over-Union）指标等评价指标。
from optimizer_loss import Optimizer

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import torch.nn.functional as F

import torch.distributed as dist
# 用于支持分布式训练的模块。通过使用 torch.distributed 可以将深度学习模型训练分布式地运行在多个计算机或 GPU 上，从而加速训练过程和提高模型性能。
"""
import torch
import torch.nn as nn
import torch.optim as optim
import torch.distributed as dist
import torch.multiprocessing as mp

# 定义模型
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(10, 100)
        self.fc2 = nn.Linear(100, 2)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# 定义训练函数
def train(rank, world_size):
    # 初始化进程组
    dist.init_process_group("gloo", rank=rank, world_size=world_size)
# 第一个参数指定进程组的后端类型，例如 "gloo" 表示使用 Gloo 后端，还可以选择使用 NCCL 或 MPI 等其他后端。
# 第二个参数 rank 表示当前进程在进程组中的编号（从 0 开始），第三个参数 world_size 表示进程组中总共有多少个进程。
    # 构建模型和优化器
    model = Net()
    optimizer = optim.SGD(model.parameters(), lr=0.01)

    # 将模型复制到每个 GPU 上
    model = nn.parallel.DistributedDataParallel(model, device_ids=[rank])

    # 构造训练数据
    data = torch.randn(64, 10).to(rank)

    # 训练 100 轮
    for epoch in range(100):
        optimizer.zero_grad()
        output = model(data)
        loss = nn.functional.cross_entropy(output, torch.LongTensor([0, 1]).to(rank))
        loss.backward()
        optimizer.step()

        if rank == 0 and epoch % 10 == 0:
            print("Epoch {} loss: {:.4f}".format(epoch, loss.item()))

    # 释放进程组资源
    dist.destroy_process_group()

if __name__ == "__main__":
    # 启动 2 个进程并行训练
    mp.spawn(train, args=(2,), nprocs=2, join=True)
"""

import os
import os.path as osp
import time
import datetime
import argparse  
# 命令行参数解析模块，可以帮助我们更方便地处理命令行输入的参数
# 可以定义程序需要接受哪些命令行参数，并指定它们的类型、默认值、描述等信息。它还可以自动生成帮助文档，提高了程序的可读性和易用性。
"""
import argparse

# 定义命令行参数
parser = argparse.ArgumentParser(description='This is a demo for argparse')
parser.add_argument('--num', type=int, default=1, help='an integer to show how many times to print')

# 解析命令行参数
args = parser.parse_args()

# 使用命令行参数
for i in range(args.num):
    print('Hello, world!')
"""

import logging
# 创建 logger 对象
# 通过 getLogger() 方法获取一个 logger 对象，然后可以使用该对象来记录日志信息。
logger = logging.getLogger()
"""
import logging
# 创建 logger 对象
logger = logging.getLogger()
# 配置 logger 对象，配置为记录 INFO 级别及以上的日志信息
logger.setLevel(logging.INFO)

# 创建控制台输出句柄
console_handler = logging.StreamHandler()
# 设置级别
console_handler.setLevel(logging.INFO)
# 设置输出格式
console_formatter = logging.Formatter('[%(levelname)s] %(message)s')
console_handler.setFormatter(console_formatter)

# 添加控制台输出句柄到 logger 对象
logger.addHandler(console_handler)
# 记录日志信息
logger.info('Hello, world!')
"""

# 布尔值判断
def str2bool(v):
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
        return False
    else:
        raise argparse.ArgumentTypeError('Unsupported value encountered.')

# 定义添加参数
def parse_args():
    parse = argparse.ArgumentParser()
    parse.add_argument(
            '--local_rank',
            dest = 'local_rank',
            type = int,
            default = -1,
            )
            # train进程个数8
    parse.add_argument(
            '--n_workers_train',
            dest = 'n_workers_train',
            type = int,
            default = 8,
            )
            # val进程个数0
    parse.add_argument(
            '--n_workers_val',
            dest = 'n_workers_val',
            type = int,
            default = 0,
            )
            # add_argument() 方法：用于向解析器中添加参数；
            # --n_workers_val：命令行参数名称，表示验证集数据加载时使用的进程数；
            # dest 参数：用于指定将参数值存储到哪个属性中；
            # type 参数：用于指定参数值的类型，此处使用了 int 类型，将参数值转换为整数类型；
            # default 参数：用于指定当未提供该参数时，应当使用的默认值。
            
            # 每个gpu分8个图像
    parse.add_argument(
            '--n_img_per_gpu',
            dest = 'n_img_per_gpu',
            type = int,
            default = 16,
            )
    parse.add_argument(
            '--max_iter',
            dest = 'max_iter',
            type = int,
            default = 40000,
            )
    parse.add_argument(
            '--save_iter_sep',
            dest = 'save_iter_sep',
            type = int,
            default = 1000,
            )
    parse.add_argument(
            '--warmup_steps',
            dest = 'warmup_steps',
            type = int,
            default = 1000,
            )      
    parse.add_argument(
            '--mode',
            dest = 'mode',
            type = str,
            default = 'train',
            )
    parse.add_argument(
            '--ckpt',
            dest = 'ckpt',
            type = str,
            default = None,
            )
    parse.add_argument(
            '--respath',
            dest = 'respath',
            type = str,
            default = None,
            )
    parse.add_argument(
            '--backbone',
            dest = 'backbone',
            type = str,
            default = 'CatNetSmall',
            )
    parse.add_argument(
            '--pretrain_path',
            dest = 'pretrain_path',
            type = str,
            default = '',
            )
    parse.add_argument(
            '--use_conv_last',
            dest = 'use_conv_last',
            type = str2bool,
            default = False,
            )
            # use_boundary_16、se_boundary_8、use_boundary_4、use_boundary_2 等变量则与具体的图像分割模型实现相关，表示是否使用不同大小的边界（如 2、4、8、16）作为训练数据。
    parse.add_argument(
            '--use_boundary_2',
            dest = 'use_boundary_2',
            type = str2bool,
            default = False,
            )
    parse.add_argument(
            '--use_boundary_4',
            dest = 'use_boundary_4',
            type = str2bool,
            default = False,
            )
    parse.add_argument(
            '--use_boundary_8',
            dest = 'use_boundary_8',
            type = str2bool,
            default = False,
            )
    parse.add_argument(
            '--use_boundary_16',
            dest = 'use_boundary_16',
            type = str2bool,
            default = False,
            )
    return parse.parse_args()

# 训练
def train():
    args = parse_args()
    # 设置参数保存路径
    save_pth_path = os.path.join(args.respath, 'pths')
    dspth = './data'
    
    # print(save_pth_path)
    # print(osp.exists(save_pth_path))
    # if not osp.exists(save_pth_path) and dist.get_rank()==0: 
    # 如果没有save_pth_path文件，创建一个这样的文件夹
    if not osp.exists(save_pth_path):
        os.makedirs(save_pth_path)
        
        
        torch.cuda.set_device(args.local_rank)
        # 初始化进程组
        dist.init_process_group(
                backend = 'nccl',
                init_method = 'tcp://127.0.0.1:33274',
                world_size = torch.cuda.device_count(),
                # 进程数等于cuda设备数量
                rank=args.local_rank
                # 在实际运行中，通常需要通过命令行参数来指定当前进程的编号
                )
               # backend = 'nccl'：指定了后端类型为 NCCL，即使用 NVIDIA 提供的用于 GPU 间通信的库进行分布式训练。
               # init_method = 'tcp://127.0.0.1:33274'：指定了初始化方法为 TCP，使用指定的 IP 地址和端口号与其他进程建立连接。这里的 IP 地址和端口号需要根据实际情况设置。
               # world_size = torch.cuda.device_count()：指定了进程组的总大小为当前 CUDA 设备的数量，即每个设备对应一个进程。
               # rank=args.local_rank：指定当前进程在进程组中的编号，该值从命令行参数 --local_rank 中获取。
  # 第一个参数指定进程组的后端类型，例如 "gloo" 表示使用 Gloo 后端，还可以选择使用 NCCL 或 MPI 等其他后端。
  # 第二个参数 rank 表示当前进程在进程组中的编号（从 0 开始），第三个参数 world_size 表示进程组中总共有多少个进程。  
  
        #  是一个自定义的函数，它用于设置日志记录器，在指定路径下生成日志文件
        setup_logger(args.respath)
        
        ## dataset
        # 19个类别
        n_classes = 19
        n_img_per_gpu = args.n_img_per_gpu
        n_workers_train = args.n_workers_train
        n_workers_val = args.n_workers_val
        use_boundary_16 = args.use_boundary_16
        se_boundary_8 = args.use_boundary_8
        use_boundary_4 = args.use_boundary_4
        use_boundary_2 = args.use_boundary_2

   # dist在哪，是什么
   # 用于判断当前进程是否为分布式训练中的主进程（rank=0）
   # dist 表示 PyTorch 中用于实现分布式训练的模块，其中包含了用于获取进程 rank 号的方法；
   # get_rank() 方法：返回当前进程的 rank 号，其中主进程的 rank 号默认为 0；
    if dist.get_rank()==0: 
        logger.info('n_workers_train: {}'.format(n_workers_train))
        logger.info('n_workers_val: {}'.format(n_workers_val))
        logger.info('use_boundary_2: {}'.format(use_boundary_2))
        logger.info('use_boundary_4: {}'.format(use_boundary_4))
        logger.info('use_boundary_8: {}'.format(use_boundary_8))
        logger.info('use_boundary_16: {}'.format(use_boundary_16))
        logger.info('mode: {}'.format(args.mode))
        
        
   # mode 变量表示数据增强的模式，该模式决定了使用哪种数据增强方式；
   # cropsize 是一个列表，表示图像随机裁剪后的大小，具体来说，它包含了两个元素，分别表示裁剪后的长和宽；
   # 而 randomscale 则是一个由多个浮点数构成的元组，表示图像的尺度变换系数，用于在训练时对图像进行缩放以此实现数据增强。
   mode = args.mode
   cropsize = [1024, 512]
   randomscale = (0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1.0, 1.125, 1.25, 1.375, 1.5)
   
    # 对数据做数据增强，保存在dspth路径中
    ds = CityScapes(dspth, cropsize=cropsize, mode=mode, randomscale=randomscale)
    # 创建一个分布式数据采样器（DistributedSampler），以便在分布式训练中对数据集进行划分和采样
    # 得出一个数据样本，类似于split
    sampler = torch.utils.data.distributed.DistributedSampler(ds)
    # 创建一个 PyTorch 中的数据加载器（DataLoader），以便在训练过程中对数据集进行批量读取和处理
    dl = DataLoader(ds,
                    batch_size = n_img_per_gpu,
                    shuffle = False,
                    sampler = sampler,
                    num_workers = n_workers_train,
                    pin_memory = False,
                    drop_last = True)
    # pin_memory：表示是否将内存锁定到 RAM 中。如果为 True，则会将数据从主机端内存锁定到 RAM 中，可以加速数据传输，但会占用更多的系统内存；
    # drop_last：表示是否丢弃最后一组大小小于 batch_size 的数据，如果为 True，则表示最后一组大小小于 batch_size 的数据不进行训练，否则会进行处理。
    # shuffle 参数表示是否对数据集进行随机打乱。如果该参数为 True，则在每个 epoch 开始时，数据加载器会将数据集中的所有样本打乱重新排列；
    # 如果该参数为 False，则不对数据集进行打乱操作，按照原始顺序进行训练。
    # 一般来说，在训练过程中对数据进行随机打乱可以增加模型的鲁棒性和泛化能力，避免网络过度拟合训练数据，提高网络的训练效果。但是，对于某些特定的任务或数据集，也可能需要保持数据集的原始顺序进行训练
    
                    
    # exit(0)
    # mode='val'，上次有赋值，这次没有定义
    # 这次数据也放在这里，不会冲突吧，这次应该是用上面的数据进行测试，名叫'val'
    dsval = CityScapes(dspth, mode='val', randomscale=randomscale)
    sampler_val = torch.utils.data.distributed.DistributedSampler(dsval)
    dlval = DataLoader(dsval,
                    batch_size = 2,
                    shuffle = False,
                    sampler = sampler_val,
                    num_workers = n_workers_val,
                    drop_last = False)
    
    
    ## model
    
    # 忽略指定的标签类别
    ignore_idx = 255
    net = BiSeNet(backbone=args.backbone, n_classes=n_classes, pretrain_model=args.pretrain_path, 
    use_boundary_2=use_boundary_2, use_boundary_4=use_boundary_4, use_boundary_8=use_boundary_8, 
    use_boundary_16=use_boundary_16, use_conv_last=args.use_conv_last)
    
    # args.ckpt 表示预训练模型的路径
    if not args.ckpt is None:
    # 从 GPU 加载的预训练模型参数转换到 CPU 上，以便后续的训练和推理
    # torch.load加载模型参数的函数，可以将保存在文件中的模型参数加载到指定的网络结构中
        net.load_state_dict(torch.load(args.ckpt, map_location='cpu'))
        
    # 将模型移动到 GPU 上进行训练
    net.cuda()
    # 设置模型为训练模式，以便在后续的训练过程中进行反向传播和参数更新
    net.train()
    # PyTorch 中用于实现分布式计算的模块，可以对模型进行多进程数据并行处理，从而提高训练速度和效率；
    net = nn.parallel.DistributedDataParallel(net,
            device_ids = [args.local_rank, ],
            output_device = args.local_rank,
            find_unused_parameters=True
            )
    # 指定哪些设备用于训练，此处使用了 [args.local_rank, ]，表示仅使用当前进程所在的 GPU 设备进行训练
    # 指定输出结果的设备，此处也使用了 args.local_rank，表示将输出结果返回到当前进程所在的 GPU 设备上
    # find_unused_parameters=True 参数：表示开启自动发现未使用的参数（Unused Parameters），即当某个进程的计算已经完成时，无需等待其他进程，直接跳过计算未使用的参数，从而加快训练速度。
              
         
    # 分数阈值
    score_thres = 0.7
    # 最小保留样本数的阈值为  每个gpu上的图象数量 * 图像裁剪后的长 * 图像裁剪后的宽  除以16
    n_min = n_img_per_gpu * cropsize[0] * cropsize[1]//16
    
    # 创建三个损失函数对象，分别用于计算图像语义分割任务中的不同尺度下的损失值
    criteria_p = OhemCELoss(thresh=score_thres, n_min=n_min, ignore_lb=ignore_idx)
    criteria_16 = OhemCELoss(thresh=score_thres, n_min=n_min, ignore_lb=ignore_idx)
    criteria_32 = OhemCELoss(thresh=score_thres, n_min=n_min, ignore_lb=ignore_idx)
    # OhemCELoss：是一个自定义的 PyTorch 损失函数类，用于计算图像语义分割任务中的损失值。该函数的具体实现方式可以根据需求进行修改；
    # thresh 参数：表示损失函数中用于过滤掉一些误分类样本的阈值，即当某个像素点预测的概率小于这个阈值时，将其视为背景像素，不参与损失值的计算；
    # n_min 参数：表示损失函数中用于设置最小保留样本数的阈值，即在每个 mini-batch 中至少保留 n_min 个正样本和 n_min 个负样本用于损失值的计算；
    # ignore_lb 参数：表示忽略掉某些指定的标签类别，不参与损失值的计算；
    # criteria_p、criteria_16 和 criteria_32：是三个不同尺度下的损失函数对象，分别对应着全分辨率（full resolution）、1/16 分辨率和 1/32 分辨率下的损失值计算。
    
    # 创建一个自定义的损失函数对象 boundary_loss_func，该损失函数主要用于计算图像分割任务中的边界细节损失值。
    # DetailAggregateLoss：是一个自定义的 PyTorch 损失函数类，用于计算图像分割任务中的边界细节损失值。该函数的具体实现方式可以根据需求进行修改；
    # boundary_loss_func：表示用于计算边界细节损失值的损失函数对象，可以通过调用 DetailAggregateLoss 类的构造方法来创建。
    boundary_loss_func = DetailAggregateLoss()
    
    ## optimizer
    
    # maxmIOU50 和 maxmIOU75：分别表示训练过程中 IoU 指标达到 50% 和 75% 时的最大值，用于记录模型在验证集上的最佳表现；
    maxmIOU50 = 0.
    maxmIOU75 = 0.
    # momentum：表示动量（momentum）系数，用于控制梯度更新的速度和方向。在优化器的 SGD 更新过程中，会将之前的梯度信息融入到当前梯度中，加速收敛并减少震荡；
    momentum = 0.9
    # weight_decay：表示权重衰减（weight decay）系数，用于控制网络权重的正则化强度。通过惩罚较大的权重，可以防止网络过度拟合训练数据。
    weight_decay = 5e-4
    # 初始学习率，以便在训练初期能够快速收敛，并逐渐降低学习率以防止过度拟合，
    # 较大的初始学习率可以加快模型的收敛速度，但也可能导致模型无法收敛或震荡不定；较小的初始学习率则会减缓训练速度，但更容易保证模型收敛稳定
    lr_start = 1e-2
    # max_iter：表示模型最大训练迭代次数；40000
    max_iter = args.max_iter
    # save_iter_sep：表示每隔多少个 mini-batch 保存一次模型参数；1000
    save_iter_sep = args.save_iter_sep
    # power：表示学习率调度策略中的指数衰减系数，用于控制学习率的衰减速率
    power = 0.9
    # warmup_steps：表示模型开始训练时的预热步数，即在预热阶段内逐渐增加学习率，以便尽快达到较高的训练效果 1000
    warmup_steps = args.warmup_steps
    # warmup_start_lr：表示模型开始训练时的初始学习率，用于控制预热阶段学习率的大小。
    warmup_start_lr = 1e-5
"""
warmup_start_lr：表示模型开始训练时的预热阶段的初始学习率，该阶段的目的通常是为了快速收敛，并尽快达到较高的训练效果。
在预热阶段内，学习率通常设置得比较小，以便在这个阶段内探索数据集的特征，并减少因学习率设置不当而导致的震荡和不稳定性。
lr_start：表示模型训练过程中的初始学习率，通常需要根据具体任务和网络结构进行调整。
在训练初期，较大的初始学习率可以加快模型的收敛速度，同时也可能导致模型无法收敛或震荡不定；较小的初始学习率则会减缓训练速度，但更容易保证模型收敛稳定。

线性增加：学习率可以按照线性函数进行增加，例如初始学习率为 1e-5，每个 mini-batch 增加 1e-5，直到达到预设的最大值。
指数增加：学习率可以按照指数函数进行增加，例如初始学习率为 1e-5，每个 mini-batch 增加指数函数（如 ）的结果，直到达到预设的最大值。
多项式函数增加：学习率可以按照多项式函数进行增加，例如初始学习率为 1e-5，每个 mini-batch 增加多项式函数的结果（如 ），直到达到预设的最大值。
"""

     if dist.get_rank()==0: 
        print('max_iter: ', max_iter)
        print('save_iter_sep: ', save_iter_sep)
        print('warmup_steps: ', warmup_steps)
        
     optim = Optimizer(
            model = net.module,
            loss = boundary_loss_func,
            lr0 = lr_start,
            momentum = momentum,
            wd = weight_decay,
            warmup_steps = warmup_steps,
            warmup_start_lr = warmup_start_lr,
            max_iter = max_iter,
            power = power)
            
            
     ## train loop
     
     # 每隔多少次迭代输出一次日志信息
     msg_iter = 50
     # 记录总体平均损失
     loss_avg = []
     # 边界 BCE 损失
     loss_boundery_bce = []
     # 边界 Dice 损失
     loss_boundery_dice = []
     # 获取到的时间戳值，记录整个训练开始的时间
     st = glob_st = time.time()
     # 初始化一个数据集迭代器 diter
     diter = iter(dl)
     # 记录当前的训练轮数
     epoch = 0
     # 进行 max_iter 次迭代
     for it in range(max_iter):
     # 尝试从数据集迭代器中获取一个 mini-batch 的数据，如果已达到数据集末尾，则更新 epoch，并重新初始化数据集迭代器
         try:
             # 获取迭代器中下一个 mini-batch 的输入图像 im 和标签 lb
             im, lb = next(diter)
             # 如果当前 mini-batch 中输入图像数量不足 n_img_per_gpu，则说明已经遍历完了整个数据集，此时抛出 StopIteration 异常
             if not im.size()[0]==n_img_per_gpu: raise StopIteration
             # 异常，说明此轮完成，接着下一轮次
             # 如果捕获到 StopIteration 异常，则说明已经遍历完了整个数据集，此时更新 epoch 计数器，并重新初始化数据集迭代器和采样器
         except StopIteration：
             epoch += 1
             # 通过设置采样器的 epoch 属性来确保每个 epoch 中采样的顺序不同
             sampler.set_epoch(epoch)
             # 重新初始化数据集迭代器
             diter = iter(dl)
             # 继续获取下一个 mini-batch 的输入图像和标签
             im, lb = next(diter)
             
         # 将输入图像转移到 GPU 上进行计算
         im = im.cuda()
         # 将标签信息转移到 GPU 上进行计算
         lb = lb.cuda()
         # 获取输入图像的高度和宽度信息，第一个为通道数
         H, W = im.size()[2:]
         # 去除标签张量的通道维度
         lb = torch.squeeze(lb, 1)
"""

"""
         # 清除梯度  优化器会遍历所有已注册的模型参数，并将它们的梯度设置为 0。这样做的目的是为了防止当前梯度与上一次梯度累加而导致不正确的更新结果
         optim.zero_grad()
         
         # 是否使用尺度为 2、4 和 8 的特征图，如果使用，则将输入图像 im 输入到神经网络 net 中，并输出包括全分辨率预测 out、下采样 2 倍分辨率预测 out16、下采样 4 倍分辨率预测 out32、
         # 尺度为 2 的细节图 detail2、尺度为 4 的细节图 detail4 和尺度为 8 的细节图 detail8
         if use_boundary_2 and use_boundary_4 and use_boundary_8:
             out, out16, out32, detail2, detail4, detail8 = net(im)
        
         if (not use_boundary_2) and use_boundary_4 and use_boundary_8:
             out, out16, out32, detail4, detail8 = net(im)

         if (not use_boundary_2) and (not use_boundary_4) and use_boundary_8:
             out, out16, out32, detail8 = net(im)

         if (not use_boundary_2) and (not use_boundary_4) and (not use_boundary_8):
             out, out16, out32 = net(im)

         lossp = criteria_p(out, lb)
         loss2 = criteria_16(out16, lb)
         loss3 = criteria_32(out32, lb)
        
"""
全分辨率预测 out 是指在原始分辨率上进行预测的结果，具有最高的空间分辨率；
下采样 2 倍分辨率预测 out16 是指将输入图像下采样 2 倍后进行预测的结果，具有一定的空间信息损失；
下采样 4 倍分辨率预测 out32 是指将输入图像下采样 4 倍后进行预测的结果，空间信息更少。
而细节图则是指对应尺度下的细节增强信息，可以用于提高预测的精度和鲁棒性。

通过多个尺度的特征图进行预测，可以有效地提高模型的性能和泛化能力，使其适用于不同尺寸和分辨率的输入图像。
同时，在多尺度预测的过程中，可以利用不同分辨率下的细节信息进行特征增强和误差修复，从而提高模型对图像细节的感知能力。
"""

         boundery_bce_loss = 0.
         boundery_dice_loss = 0.
         
         if use_boundary_2: 
             # if dist.get_rank()==0:
             #     print('use_boundary_2')
             boundery_bce_loss2,  boundery_dice_loss2 = boundary_loss_func(detail2, lb)
             boundery_bce_loss += boundery_bce_loss2
             boundery_dice_loss += boundery_dice_loss2
        
         if use_boundary_4:
              # if dist.get_rank()==0:
              #     print('use_boundary_4')
              boundery_bce_loss4,  boundery_dice_loss4 = boundary_loss_func(detail4, lb)
              boundery_bce_loss += boundery_bce_loss4
              boundery_dice_loss += boundery_dice_loss4

         if use_boundary_8:
              # if dist.get_rank()==0:
              #     print('use_boundary_8')
              boundery_bce_loss8,  boundery_dice_loss8 = boundary_loss_func(detail8, lb)
              boundery_bce_loss += boundery_bce_loss8
              boundery_dice_loss += boundery_dice_loss8
              
         loss = lossp + loss2 + loss3 + boundery_bce_loss + boundery_dice_loss
         
        # 反向传播计算梯度
         loss.backward()
         # 更新模型参数
         optim.step()

         loss_avg.append(loss.item())

         loss_boundery_bce.append(boundery_bce_loss.item())
         loss_boundery_dice.append(boundery_dice_loss.item())
         
         
        ## print training log message
        
        # msg_iter=50，it=0，从0开始到49，每50一轮
        if (it+1) % msg_iter==0:
            # 平均损失
            loss_avg = sum(loss_avg) / len(loss_avg)
            lr = optim.lr
            # 获取到的时间戳值，记录训练的结束时间
            ed = time.time()
            # t_intv已经训练的时间
            t_intv, glob_t_intv = ed - st, ed - glob_st
            # 计算后面训练所需的时间
            eta = int((max_iter - it) * (glob_t_intv / it))
            # 以秒为单位的时间差 eta 转换为以时分秒格式表示的字符串
            # datetime.timedelta 是 Python 内置模块，用于表示时间间隔或持续时间
            eta = str(datetime.timedelta(seconds=eta))
            
            # 平均损失
            loss_boundery_bce_avg = sum(loss_boundery_bce) / len(loss_boundery_bce)
            loss_boundery_dice_avg = sum(loss_boundery_dice) / len(loss_boundery_dice)
            msg = ', '.join([
                'it: {it}/{max_it}',
                'lr: {lr:4f}',
                'loss: {loss:.4f}',
                'boundery_bce_loss: {boundery_bce_loss:.4f}',
                'boundery_dice_loss: {boundery_dice_loss:.4f}',
                'eta: {eta}',
                'time: {time:.4f}',
            ]).format(
                it = it+1,
                max_it = max_iter,
                lr = lr,
                loss = loss_avg,
                boundery_bce_loss = loss_boundery_bce_avg,
                boundery_dice_loss = loss_boundery_dice_avg,
                time = t_intv,
                eta = eta
            )
            
            logger.info(msg)
            # 损失清空
            loss_avg = []
            loss_boundery_bce = []
            loss_boundery_dice = []
            # 时间继上
            st = ed
         
         
        # print(boundary_loss_func.get_params())
        # 每隔save_iter_sep保存一次模型参数
        if (it+1) % save_iter_sep==0:
        # and it != 0:
            
            ## model
            logger.info('evaluating the model ...')
            logger.info('setup and restore model')
            # 用于将神经网络模型设置为评估模式的方法。在评估模式下，模型会禁用部分操作，
            # 例如 dropout 和批归一化层，这些操作通常只在训练时使用。这可以确保模型针对给定输入生成一致和确定性的输出，这在评估模型性能或对新数据进行预测时非常重要
            net.eval()

            # evaluator
            logger.info('compute the mIOU')
            # no_grad() 上下文管理器，它可以临时禁用梯度计算
            with torch.no_grad():
            # single_scale1 和 single_scale2 分别进行模型评估，并计算了两种不同比例的图像尺度下的 mIOU 指标值
                single_scale1 = MscEvalV0()
                mIOU50 = single_scale1(net, dlval, n_classes)

                single_scale2= MscEvalV0(scale=0.75)
                mIOU75 = single_scale2(net, dlval, n_classes)
                
            #  round() 函数将变量 mIOU75 的值四舍五入到小数点后四位
            save_pth = osp.join(save_pth_path, 'model_iter{}_mIOU50_{}_mIOU75_{}.pth'
            .format(it+1, str(round(mIOU50,4)), str(round(mIOU75,4))))
            
            # 代码检查 net 是否具有 module 属性，如果有，则表示使用了多 GPU 训练，需要访问 net.module 的属性。
            # 否则，直接访问 net 的属性。然后，将获得的状态字典保存到指定的文件路径 save_pth 中。
            # 最后，仅在分布式训练中，进程等级为 0 的进程才会执行保存操作，避免多个进程同时写入同一个文件。
            state = net.module.state_dict() if hasattr(net, 'module') else net.state_dict()
            if dist.get_rank()==0: 
                torch.save(state, save_pth)

            logger.info('training iteration {}, model saved to: {}'.format(it+1, save_pth))

            if mIOU50 > maxmIOU50:
                maxmIOU50 = mIOU50
                save_pth = osp.join(save_pth_path, 'model_maxmIOU50.pth'.format(it+1))
                state = net.module.state_dict() if hasattr(net, 'module') else net.state_dict()
                if dist.get_rank()==0: 
                    torch.save(state, save_pth)
                    
                logger.info('max mIOU model saved to: {}'.format(save_pth))
            
            if mIOU75 > maxmIOU75:
                maxmIOU75 = mIOU75
                save_pth = osp.join(save_pth_path, 'model_maxmIOU75.pth'.format(it+1))
                state = net.module.state_dict() if hasattr(net, 'module') else net.state_dict()
                if dist.get_rank()==0: 
                    torch.save(state, save_pth)
                    
                logger.info('max mIOU model saved to: {}'.format(save_pth))
            
            logger.info('mIOU50 is: {}, mIOU75 is: {}'.format(mIOU50, mIOU75))
            logger.info('maxmIOU50 is: {}, maxmIOU75 is: {}.'.format(maxmIOU50, maxmIOU75))
            # 每次评估完后，保存参数，接下来一轮训练，
            net.train() 

    ## dump the final model
    save_pth = osp.join(save_pth_path, 'model_final.pth')
    net.cpu()
    state = net.module.state_dict() if hasattr(net, 'module') else net.state_dict()
    if dist.get_rank()==0: 
        torch.save(state, save_pth)
        
    logger.info('training done, model saved to: {}'.format(save_pth))
    print('epoch: ', epoch)

if __name__ == "__main__":
    train()


